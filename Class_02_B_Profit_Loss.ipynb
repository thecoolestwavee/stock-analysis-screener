{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71152cc1-c478-4bd9-8a85-4736ce7156b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Class_02_B: Financial Metrics Extractor (FIXED)\n",
      "==================================================\n",
      "ğŸ“¡ Fetching data from: https://www.screener.in/company/RELIANCE/consolidated/\n",
      "âœ… Page fetched successfully!\n",
      "ğŸ¢ Company identified as: Reliance_Industries_Ltd\n",
      "\n",
      "ğŸ” Starting financial metrics extraction...\n",
      "ğŸ“Š Found 11 tables to analyze\n",
      "   ğŸ¯ Found Compounded Sales Growth in table 3\n",
      "     âœ… 10 Years: 10%\n",
      "     âœ… 5 Years: 10%\n",
      "     âœ… 3 Years: 11%\n",
      "     âœ… TTM: 6%\n",
      "   ğŸ¯ Found Compounded Profit Growth in table 4\n",
      "     âœ… 10 Years: 12%\n",
      "     âœ… 5 Years: 10%\n",
      "     âœ… 3 Years: 5%\n",
      "     âœ… TTM: 9%\n",
      "   ğŸ¯ Found Stock Price CAGR in table 5\n",
      "     âœ… 10 Years: 22%\n",
      "     âœ… 5 Years: 7%\n",
      "     âœ… 3 Years: 5%\n",
      "     âœ… 1 Year: -11%\n",
      "   ğŸ¯ Found Return on Equity in table 6\n",
      "     âœ… 10 Years: 9%\n",
      "     âœ… 5 Years: 8%\n",
      "     âœ… 3 Years: 9%\n",
      "     âœ… Last Year: 8%\n",
      "   ğŸ” Using text pattern extraction...\n",
      "   ğŸ“ Found Compounded Sales Growth at position 9729\n",
      "     âœ… 10 Years: 10%\n",
      "     âœ… 5 Years: 10%\n",
      "     âœ… 3 Years: 11%\n",
      "     âœ… TTM: 6%\n",
      "   ğŸ“ Found Compounded Profit Growth at position 9813\n",
      "     âœ… 10 Years: 12%\n",
      "     âœ… 5 Years: 10%\n",
      "     âœ… 3 Years: 5%\n",
      "     âœ… TTM: 9%\n",
      "   ğŸ“ Found Stock Price CAGR at position 9897\n",
      "     âœ… 10 Years: 22%\n",
      "     âœ… 5 Years: 7%\n",
      "     âœ… 3 Years: 5%\n",
      "     âœ… 1 Year: -11%\n",
      "   ğŸ“ Found Return on Equity at position 9977\n",
      "     âœ… 10 Years: 9%\n",
      "     âœ… 5 Years: 8%\n",
      "     âœ… 3 Years: 9%\n",
      "     âœ… Last Year: 8%\n",
      "ğŸ“Š Found 1 ratio sections\n",
      "\n",
      "============================================================\n",
      "ğŸ“ˆ FINANCIAL METRICS EXTRACTION RESULTS\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Compounded Sales Growth:\n",
      "   10 Years:\t10%\n",
      "   5 Years:\t10%\n",
      "   3 Years:\t11%\n",
      "   TTM:\t6%\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“Š Compounded Profit Growth:\n",
      "   10 Years:\t12%\n",
      "   5 Years:\t10%\n",
      "   3 Years:\t5%\n",
      "   TTM:\t9%\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“Š Stock Price CAGR:\n",
      "   10 Years:\t22%\n",
      "   5 Years:\t7%\n",
      "   3 Years:\t5%\n",
      "   1 Year:\t-11%\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“Š Return on Equity:\n",
      "   10 Years:\t9%\n",
      "   5 Years:\t8%\n",
      "   3 Years:\t9%\n",
      "   Last Year:\t8%\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“‹ SUMMARY:\n",
      "   Total data points extracted: 16\n",
      "   Sections with data: 4/4\n",
      "\n",
      "ğŸ’¾ CSV data saved to: extracted_data/financial_metrics/csv/Reliance_Industries_Ltd_financial_metrics_20250902_083918.csv\n",
      "ğŸ’¾ JSON backup saved to: extracted_data/financial_metrics/json/Reliance_Industries_Ltd_financial_metrics_20250902_083918.json\n",
      "ğŸ“Š Summary CSV saved to: extracted_data/financial_metrics/csv/Reliance_Industries_Ltd_summary_20250902_083918.csv\n",
      "\n",
      "âœ… Class_02_B completed successfully!\n",
      "âœ… Files saved in organized folder structure\n",
      "ğŸ“ CSV: extracted_data/financial_metrics/csv/Reliance_Industries_Ltd_financial_metrics_20250902_083918.csv\n",
      "ğŸ“ JSON: extracted_data/financial_metrics/json/Reliance_Industries_Ltd_financial_metrics_20250902_083918.json\n",
      "ğŸ“ Summary: extracted_data/financial_metrics/csv/Reliance_Industries_Ltd_summary_20250902_083918.csv\n",
      "\n",
      "ğŸ“ Folder Structure Created:\n",
      "ğŸ“ extracted_data/\n",
      "   ğŸ“ financial_metrics/\n",
      "      ğŸ“ csv/          <- Detailed & Summary CSV files\n",
      "      ğŸ“ json/         <- JSON backup files\n",
      "\n",
      "ğŸ“ Next Steps:\n",
      "- Open CSV files in Excel/Google Sheets for analysis\n",
      "- Use summary CSV to compare multiple companies\n",
      "- Ready for Class_03 (combining basic + financial data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nCLASS_02_B IMPROVEMENTS - CSV FILE MANAGEMENT:\\n\\n1. **ORGANIZED FOLDER STRUCTURE**:\\n   ğŸ“ extracted_data/\\n      ğŸ“ financial_metrics/\\n         ğŸ“ csv/     <- CSV files for spreadsheet analysis\\n         ğŸ“ json/    <- JSON backup files\\n\\n2. **TWO TYPES OF CSV FILES**:\\n   - **Detailed CSV**: Each metric as separate rows\\n   - **Summary CSV**: All metrics in one row (great for comparing companies)\\n\\n3. **AUTOMATIC FILE NAMING**:\\n   - Extracts company name from page\\n   - Adds timestamp to prevent overwrites\\n   - Example: \"Reliance_Industries_Ltd_financial_metrics_20241201_143022.csv\"\\n\\n4. **CROSS-CHECKING FEATURES**:\\n   - Both CSV and JSON saved for verification\\n   - Summary format perfect for Excel pivot tables\\n   - Timestamped files for tracking data changes\\n\\n5. **FOLDER AUTO-CREATION**:\\n   - Script creates all necessary folders automatically\\n   - Organized structure for multiple companies\\n   - Easy to backup and share data files\\n\\nNOW YOUR DATA IS SAVED AS CSV IN ORGANIZED FOLDERS! ğŸ“ŠğŸ“\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class_02_B: Financial Metrics Extractor from Screener.in (FIXED VERSION)\n",
    "# Target: Extract Compounded Growth, CAGR, and ROE data\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "class ScreenerFinancialExtractor:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the extractor with headers to mimic browser request\n",
    "        \"\"\"\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "        \n",
    "    def fetch_page(self, url):\n",
    "        \"\"\"\n",
    "        Fetch the webpage content\n",
    "        Args: url (str) - Screener.in company URL\n",
    "        Returns: BeautifulSoup object or None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(f\"ğŸ“¡ Fetching data from: {url}\")\n",
    "            response = requests.get(url, headers=self.headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            print(\"âœ… Page fetched successfully!\")\n",
    "            return soup\n",
    "            \n",
    "        except requests.RequestException as e:\n",
    "            print(f\"âŒ Error fetching page: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_financial_metrics(self, soup):\n",
    "        \"\"\"\n",
    "        Extract the four main financial metrics sections using the correct Screener.in structure\n",
    "        Returns: Dictionary with structured financial data\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ” Starting financial metrics extraction...\")\n",
    "        \n",
    "        metrics = {\n",
    "            'compounded_sales_growth': {},\n",
    "            'compounded_profit_growth': {},\n",
    "            'stock_price_cagr': {},\n",
    "            'return_on_equity': {}\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Method 1: Find the specific tables with financial metrics\n",
    "            # Screener.in uses tables with specific patterns\n",
    "            \n",
    "            # Look for tables containing our target metrics\n",
    "            tables = soup.find_all('table')\n",
    "            print(f\"ğŸ“Š Found {len(tables)} tables to analyze\")\n",
    "            \n",
    "            for i, table in enumerate(tables):\n",
    "                table_text = table.get_text()\n",
    "                \n",
    "                # Check each metric section\n",
    "                if \"Compounded Sales Growth\" in table_text:\n",
    "                    print(f\"   ğŸ¯ Found Compounded Sales Growth in table {i+1}\")\n",
    "                    self.extract_metric_from_table(table, metrics['compounded_sales_growth'])\n",
    "                \n",
    "                elif \"Compounded Profit Growth\" in table_text:\n",
    "                    print(f\"   ğŸ¯ Found Compounded Profit Growth in table {i+1}\")\n",
    "                    self.extract_metric_from_table(table, metrics['compounded_profit_growth'])\n",
    "                \n",
    "                elif \"Stock Price CAGR\" in table_text:\n",
    "                    print(f\"   ğŸ¯ Found Stock Price CAGR in table {i+1}\")\n",
    "                    self.extract_metric_from_table(table, metrics['stock_price_cagr'])\n",
    "                \n",
    "                elif \"Return on Equity\" in table_text:\n",
    "                    print(f\"   ğŸ¯ Found Return on Equity in table {i+1}\")\n",
    "                    self.extract_metric_from_table(table, metrics['return_on_equity'])\n",
    "            \n",
    "            # Method 2: Direct text extraction for the specific Screener.in format\n",
    "            page_text = soup.get_text()\n",
    "            \n",
    "            # Extract using the exact patterns seen in the fetched data\n",
    "            self.extract_by_text_patterns(page_text, metrics)\n",
    "            \n",
    "            # Method 3: Look for div/section containers with ratios\n",
    "            ratio_sections = soup.find_all(['div', 'section'], \n",
    "                                         class_=re.compile(r'ratio|metric|growth|return', re.I))\n",
    "            print(f\"ğŸ“Š Found {len(ratio_sections)} ratio sections\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error in extraction: {e}\")\n",
    "            \n",
    "        return metrics\n",
    "    \n",
    "    def extract_metric_from_table(self, table, target_dict):\n",
    "        \"\"\"\n",
    "        Extract metrics from a specific table\n",
    "        \"\"\"\n",
    "        rows = table.find_all('tr')\n",
    "        \n",
    "        for row in rows:\n",
    "            cells = row.find_all(['td', 'th'])\n",
    "            \n",
    "            if len(cells) >= 2:\n",
    "                period = cells[0].get_text().strip()\n",
    "                value = cells[1].get_text().strip()\n",
    "                \n",
    "                # Clean up the period name and value\n",
    "                if period and value and '%' in value:\n",
    "                    # Remove extra characters and normalize\n",
    "                    period = period.replace(':', '').strip()\n",
    "                    value = value.strip()\n",
    "                    \n",
    "                    # Store the data\n",
    "                    target_dict[period] = value\n",
    "                    print(f\"     âœ… {period}: {value}\")\n",
    "    \n",
    "    def extract_by_text_patterns(self, page_text, metrics):\n",
    "        \"\"\"\n",
    "        Extract metrics using text pattern matching (specific to Screener.in format)\n",
    "        \"\"\"\n",
    "        print(\"   ğŸ” Using text pattern extraction...\")\n",
    "        \n",
    "        # Define the exact patterns we see in Screener.in\n",
    "        patterns = {\n",
    "            'compounded_sales_growth': {\n",
    "                'title': 'Compounded Sales Growth',\n",
    "                'periods': ['10 Years', '5 Years', '3 Years', 'TTM']\n",
    "            },\n",
    "            'compounded_profit_growth': {\n",
    "                'title': 'Compounded Profit Growth',\n",
    "                'periods': ['10 Years', '5 Years', '3 Years', 'TTM']\n",
    "            },\n",
    "            'stock_price_cagr': {\n",
    "                'title': 'Stock Price CAGR',\n",
    "                'periods': ['10 Years', '5 Years', '3 Years', '1 Year']\n",
    "            },\n",
    "            'return_on_equity': {\n",
    "                'title': 'Return on Equity',\n",
    "                'periods': ['10 Years', '5 Years', '3 Years', 'Last Year']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        for metric_key, pattern_info in patterns.items():\n",
    "            title = pattern_info['title']\n",
    "            periods = pattern_info['periods']\n",
    "            \n",
    "            # Find the section in text\n",
    "            title_pos = page_text.find(title)\n",
    "            if title_pos != -1:\n",
    "                print(f\"   ğŸ“ Found {title} at position {title_pos}\")\n",
    "                \n",
    "                # Get the section text (next 500 characters after title)\n",
    "                section_text = page_text[title_pos:title_pos + 500]\n",
    "                \n",
    "                # Extract each period's value\n",
    "                for period in periods:\n",
    "                    value = self.find_value_for_period(section_text, period)\n",
    "                    if value:\n",
    "                        metrics[metric_key][period] = value\n",
    "                        print(f\"     âœ… {period}: {value}\")\n",
    "    \n",
    "    def find_value_for_period(self, section_text, period):\n",
    "        \"\"\"\n",
    "        Find the percentage value for a specific time period\n",
    "        \"\"\"\n",
    "        # Create a pattern that looks for the period followed by percentage\n",
    "        # Pattern: \"10 Years: 10%\" or \"10 Years 10%\"\n",
    "        \n",
    "        patterns = [\n",
    "            rf'{re.escape(period)}[:\\s]*(-?\\d+(?:\\.\\d+)?)%',\n",
    "            rf'{re.escape(period)}[:\\s]*(-?\\d+(?:\\.\\d+)?)\\s*%',\n",
    "            rf'{re.escape(period)}.*?(-?\\d+(?:\\.\\d+)?)%'\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, section_text, re.IGNORECASE)\n",
    "            if match:\n",
    "                return f\"{match.group(1)}%\"\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def format_output(self, metrics):\n",
    "        \"\"\"\n",
    "        Format the extracted metrics for display\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸ“ˆ FINANCIAL METRICS EXTRACTION RESULTS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        sections = [\n",
    "            ('Compounded Sales Growth', metrics['compounded_sales_growth']),\n",
    "            ('Compounded Profit Growth', metrics['compounded_profit_growth']),\n",
    "            ('Stock Price CAGR', metrics['stock_price_cagr']),\n",
    "            ('Return on Equity', metrics['return_on_equity'])\n",
    "        ]\n",
    "        \n",
    "        for section_name, section_data in sections:\n",
    "            print(f\"\\nğŸ“Š {section_name}:\")\n",
    "            if section_data:\n",
    "                for period, value in section_data.items():\n",
    "                    print(f\"   {period}:\\t{value}\")\n",
    "            else:\n",
    "                print(\"   âŒ No data extracted\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "        # Summary\n",
    "        total_extracted = sum(len(section_data) for _, section_data in sections)\n",
    "        print(f\"\\nğŸ“‹ SUMMARY:\")\n",
    "        print(f\"   Total data points extracted: {total_extracted}\")\n",
    "        print(f\"   Sections with data: {sum(1 for _, section_data in sections if section_data)}/4\")\n",
    "    \n",
    "    def create_folder_structure(self):\n",
    "        \"\"\"\n",
    "        Create organized folder structure for data storage\n",
    "        \"\"\"\n",
    "        folders = [\n",
    "            'extracted_data',\n",
    "            'extracted_data/financial_metrics',\n",
    "            'extracted_data/financial_metrics/csv',\n",
    "            'extracted_data/financial_metrics/json'\n",
    "        ]\n",
    "        \n",
    "        for folder in folders:\n",
    "            if not os.path.exists(folder):\n",
    "                os.makedirs(folder)\n",
    "                print(f\"ğŸ“ Created folder: {folder}\")\n",
    "        \n",
    "        return 'extracted_data/financial_metrics'\n",
    "    \n",
    "    def save_to_csv(self, metrics, company_name=\"COMPANY\"):\n",
    "        \"\"\"\n",
    "        Save extracted metrics to CSV file in organized folder\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create folder structure\n",
    "            base_folder = self.create_folder_structure()\n",
    "            \n",
    "            # Generate filename with timestamp\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            csv_filename = f\"{base_folder}/csv/{company_name}_financial_metrics_{timestamp}.csv\"\n",
    "            \n",
    "            # Prepare data for CSV\n",
    "            csv_data = []\n",
    "            \n",
    "            # Add header\n",
    "            csv_data.append(['Metric Category', 'Time Period', 'Value'])\n",
    "            \n",
    "            # Add data rows\n",
    "            metric_names = {\n",
    "                'compounded_sales_growth': 'Compounded Sales Growth',\n",
    "                'compounded_profit_growth': 'Compounded Profit Growth',\n",
    "                'stock_price_cagr': 'Stock Price CAGR',\n",
    "                'return_on_equity': 'Return on Equity'\n",
    "            }\n",
    "            \n",
    "            for metric_key, metric_data in metrics.items():\n",
    "                category_name = metric_names.get(metric_key, metric_key)\n",
    "                \n",
    "                if metric_data:\n",
    "                    for period, value in metric_data.items():\n",
    "                        csv_data.append([category_name, period, value])\n",
    "                else:\n",
    "                    csv_data.append([category_name, 'No Data', 'N/A'])\n",
    "            \n",
    "            # Write to CSV\n",
    "            with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerows(csv_data)\n",
    "            \n",
    "            print(f\"\\nğŸ’¾ CSV data saved to: {csv_filename}\")\n",
    "            \n",
    "            # Also save JSON for backup\n",
    "            json_filename = f\"{base_folder}/json/{company_name}_financial_metrics_{timestamp}.json\"\n",
    "            with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(metrics, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"ğŸ’¾ JSON backup saved to: {json_filename}\")\n",
    "            \n",
    "            return csv_filename, json_filename\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error saving files: {e}\")\n",
    "            return None, None\n",
    "    \n",
    "    def create_summary_csv(self, metrics, company_name=\"COMPANY\"):\n",
    "        \"\"\"\n",
    "        Create a summary CSV with all metrics in one row (for easy comparison)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            base_folder = self.create_folder_structure()\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            summary_filename = f\"{base_folder}/csv/{company_name}_summary_{timestamp}.csv\"\n",
    "            \n",
    "            # Prepare headers\n",
    "            headers = ['Company', 'Date_Extracted']\n",
    "            \n",
    "            # Add all metric columns\n",
    "            metric_columns = [\n",
    "                'Sales_Growth_10Y', 'Sales_Growth_5Y', 'Sales_Growth_3Y', 'Sales_Growth_TTM',\n",
    "                'Profit_Growth_10Y', 'Profit_Growth_5Y', 'Profit_Growth_3Y', 'Profit_Growth_TTM',\n",
    "                'Stock_CAGR_10Y', 'Stock_CAGR_5Y', 'Stock_CAGR_3Y', 'Stock_CAGR_1Y',\n",
    "                'ROE_10Y', 'ROE_5Y', 'ROE_3Y', 'ROE_Last_Year'\n",
    "            ]\n",
    "            \n",
    "            headers.extend(metric_columns)\n",
    "            \n",
    "            # Prepare data row\n",
    "            data_row = [company_name, datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")]\n",
    "            \n",
    "            # Map data to columns\n",
    "            sales_data = metrics['compounded_sales_growth']\n",
    "            profit_data = metrics['compounded_profit_growth']\n",
    "            stock_data = metrics['stock_price_cagr']\n",
    "            roe_data = metrics['return_on_equity']\n",
    "            \n",
    "            # Add sales growth data\n",
    "            data_row.extend([\n",
    "                sales_data.get('10 Years', 'N/A'),\n",
    "                sales_data.get('5 Years', 'N/A'),\n",
    "                sales_data.get('3 Years', 'N/A'),\n",
    "                sales_data.get('TTM', 'N/A')\n",
    "            ])\n",
    "            \n",
    "            # Add profit growth data\n",
    "            data_row.extend([\n",
    "                profit_data.get('10 Years', 'N/A'),\n",
    "                profit_data.get('5 Years', 'N/A'),\n",
    "                profit_data.get('3 Years', 'N/A'),\n",
    "                profit_data.get('TTM', 'N/A')\n",
    "            ])\n",
    "            \n",
    "            # Add stock CAGR data\n",
    "            data_row.extend([\n",
    "                stock_data.get('10 Years', 'N/A'),\n",
    "                stock_data.get('5 Years', 'N/A'),\n",
    "                stock_data.get('3 Years', 'N/A'),\n",
    "                stock_data.get('1 Year', 'N/A')\n",
    "            ])\n",
    "            \n",
    "            # Add ROE data\n",
    "            data_row.extend([\n",
    "                roe_data.get('10 Years', 'N/A'),\n",
    "                roe_data.get('5 Years', 'N/A'),\n",
    "                roe_data.get('3 Years', 'N/A'),\n",
    "                roe_data.get('Last Year', 'N/A')\n",
    "            ])\n",
    "            \n",
    "            # Write to CSV\n",
    "            with open(summary_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerow(headers)\n",
    "                writer.writerow(data_row)\n",
    "            \n",
    "            print(f\"ğŸ“Š Summary CSV saved to: {summary_filename}\")\n",
    "            return summary_filename\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error creating summary CSV: {e}\")\n",
    "            return None\n",
    "            \n",
    "    def extract_company_name(self, soup):\n",
    "        \"\"\"\n",
    "        Extract company name from the page for better file naming\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Try different selectors for company name\n",
    "            title_tag = soup.find('title')\n",
    "            if title_tag:\n",
    "                title_text = title_tag.get_text()\n",
    "                # Extract company name from title (usually first part)\n",
    "                company_name = title_text.split(' share price')[0].split(' |')[0]\n",
    "                # Clean the name for filename\n",
    "                company_name = re.sub(r'[^\\w\\s-]', '', company_name).strip()\n",
    "                company_name = re.sub(r'\\s+', '_', company_name)\n",
    "                return company_name\n",
    "            \n",
    "            # Backup: try to find h1 with company name\n",
    "            h1_tag = soup.find('h1')\n",
    "            if h1_tag:\n",
    "                company_name = h1_tag.get_text().strip()\n",
    "                company_name = re.sub(r'[^\\w\\s-]', '', company_name).strip()\n",
    "                company_name = re.sub(r'\\s+', '_', company_name)\n",
    "                return company_name\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Could not extract company name: {e}\")\n",
    "            \n",
    "        return \"UNKNOWN_COMPANY\"\n",
    "        \"\"\"\n",
    "        Debug function to understand page structure better\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ”§ DEBUG: Page Structure Analysis\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Find all text containing our target words\n",
    "        page_text = soup.get_text()\n",
    "        \n",
    "        target_phrases = [\n",
    "            \"Compounded Sales Growth\",\n",
    "            \"Compounded Profit Growth\", \n",
    "            \"Stock Price CAGR\",\n",
    "            \"Return on Equity\"\n",
    "        ]\n",
    "        \n",
    "        for phrase in target_phrases:\n",
    "            pos = page_text.find(phrase)\n",
    "            if pos != -1:\n",
    "                # Show context around the phrase\n",
    "                start = max(0, pos - 50)\n",
    "                end = min(len(page_text), pos + 200)\n",
    "                context = page_text[start:end].replace('\\n', ' ').replace('  ', ' ')\n",
    "                print(f\"\\nğŸ” Found '{phrase}' at position {pos}:\")\n",
    "                print(f\"   Context: ...{context}...\")\n",
    "            else:\n",
    "                print(f\"âŒ '{phrase}' not found in page text\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function - Class_02_B Demo (FIXED VERSION)\n",
    "    \"\"\"\n",
    "    print(\"ğŸš€ Class_02_B: Financial Metrics Extractor (FIXED)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Initialize extractor\n",
    "    extractor = ScreenerFinancialExtractor()\n",
    "    \n",
    "    # Example URL (Reliance Industries)\n",
    "    url = \"https://www.screener.in/company/RELIANCE/consolidated/\"\n",
    "    \n",
    "    # You can change this URL to test with different companies\n",
    "    # url = input(\"Enter Screener.in URL: \").strip()\n",
    "    \n",
    "    # Fetch and extract\n",
    "    soup = extractor.fetch_page(url)\n",
    "    \n",
    "    if soup:\n",
    "        # Debug page structure (optional - uncomment to see page analysis)\n",
    "        # extractor.debug_page_structure(soup)\n",
    "        \n",
    "        # Extract company name for better file naming\n",
    "        company_name = extractor.extract_company_name(soup)\n",
    "        print(f\"ğŸ¢ Company identified as: {company_name}\")\n",
    "        \n",
    "        # Extract financial metrics\n",
    "        metrics = extractor.extract_financial_metrics(soup)\n",
    "        \n",
    "        # Display results\n",
    "        extractor.format_output(metrics)\n",
    "        \n",
    "        # Save to CSV and JSON files in organized folders\n",
    "        csv_file, json_file = extractor.save_to_csv(metrics, company_name)\n",
    "        \n",
    "        # Create summary CSV for easy comparison\n",
    "        summary_file = extractor.create_summary_csv(metrics, company_name)\n",
    "        \n",
    "        if csv_file and json_file:\n",
    "            print(\"\\nâœ… Class_02_B completed successfully!\")\n",
    "            print(f\"âœ… Files saved in organized folder structure\")\n",
    "            print(f\"ğŸ“ CSV: {csv_file}\")\n",
    "            print(f\"ğŸ“ JSON: {json_file}\")\n",
    "            if summary_file:\n",
    "                print(f\"ğŸ“ Summary: {summary_file}\")\n",
    "        else:\n",
    "            print(\"\\nâš ï¸ Data extraction completed but file saving failed.\")\n",
    "            \n",
    "        print(\"\\nğŸ“ Folder Structure Created:\")\n",
    "        print(\"ğŸ“ extracted_data/\")\n",
    "        print(\"   ğŸ“ financial_metrics/\")\n",
    "        print(\"      ğŸ“ csv/          <- Detailed & Summary CSV files\")\n",
    "        print(\"      ğŸ“ json/         <- JSON backup files\")\n",
    "        \n",
    "        print(\"\\nğŸ“ Next Steps:\")\n",
    "        print(\"- Open CSV files in Excel/Google Sheets for analysis\")\n",
    "        print(\"- Use summary CSV to compare multiple companies\") \n",
    "        print(\"- Ready for Class_03 (combining basic + financial data)\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ Failed to fetch page. Check URL and internet connection.\")\n",
    "\n",
    "\n",
    "# Execute if run directly\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "# ğŸ“ LEARNING NOTES FOR BEGINNERS:\n",
    "\"\"\"\n",
    "CLASS_02_B IMPROVEMENTS - CSV FILE MANAGEMENT:\n",
    "\n",
    "1. **ORGANIZED FOLDER STRUCTURE**:\n",
    "   ğŸ“ extracted_data/\n",
    "      ğŸ“ financial_metrics/\n",
    "         ğŸ“ csv/     <- CSV files for spreadsheet analysis\n",
    "         ğŸ“ json/    <- JSON backup files\n",
    "\n",
    "2. **TWO TYPES OF CSV FILES**:\n",
    "   - **Detailed CSV**: Each metric as separate rows\n",
    "   - **Summary CSV**: All metrics in one row (great for comparing companies)\n",
    "\n",
    "3. **AUTOMATIC FILE NAMING**:\n",
    "   - Extracts company name from page\n",
    "   - Adds timestamp to prevent overwrites\n",
    "   - Example: \"Reliance_Industries_Ltd_financial_metrics_20241201_143022.csv\"\n",
    "\n",
    "4. **CROSS-CHECKING FEATURES**:\n",
    "   - Both CSV and JSON saved for verification\n",
    "   - Summary format perfect for Excel pivot tables\n",
    "   - Timestamped files for tracking data changes\n",
    "\n",
    "5. **FOLDER AUTO-CREATION**:\n",
    "   - Script creates all necessary folders automatically\n",
    "   - Organized structure for multiple companies\n",
    "   - Easy to backup and share data files\n",
    "\n",
    "NOW YOUR DATA IS SAVED AS CSV IN ORGANIZED FOLDERS! ğŸ“ŠğŸ“\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363dc710-79fa-47a6-bde0-52e93f1c543a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
