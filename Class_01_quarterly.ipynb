{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e59ff232-f589-41ec-b180-e67fae834851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Selenium available - Will extract + sign expandable data\n",
      "📈 STEP 1: #quarters Section with + Sign Data\n",
      "🎯 Goal: Extract expandable data (YoY Growth, Material Cost%)\n",
      "🎯 Method: Selenium for dynamic content + basic fallback\n",
      "\n",
      "🚀 QUARTERS SECTION EXTRACTOR - STEP 1\n",
      "============================================================\n",
      "🎯 Consolidated: /company/{symbol}/consolidated/#quarters\n",
      "🎯 Standalone:   /company/{symbol}/#quarters\n",
      "📋 Extract: Quarterly Results from both URLs\n",
      "✅ Features: Skip RAW PDF, Extract + sign data, Timer\n",
      "============================================================\n",
      "⏱️  Started at: 09:20:56\n",
      "✅ Selenium WebDriver initialized\n",
      "\n",
      "🔍 Step 1: Reading symbols from: E:\\JN\\TestSymbol.csv\n",
      "📊 CSV columns found: ['SYMBOL']\n",
      "✅ Found 1 symbols using column: SYMBOL\n",
      "📋 Final symbols: ['RELIANCE']\n",
      "\n",
      "✅ Will process 1 symbols\n",
      "\n",
      "======================================== 1/1 ========================================\n",
      "🎯 Processing: RELIANCE - #quarters section\n",
      "⏱️  Symbol started at: 09:21:04\n",
      "\n",
      "📈 Step 2: Processing RELIANCE - #quarters section\n",
      "🌐 Fetching CONSOLIDATED: https://www.screener.in/company/RELIANCE/consolidated/#quarters\n",
      "🤖 Using Selenium for consolidated data...\n",
      "📊 Found 12 tables\n",
      "\n",
      "🔍 Checking table 1 for quarters data...\n",
      "   Headers: ['S.No.', 'Name', 'CMP Rs.', 'P/E', 'Mar Cap Rs.Cr.']...\n",
      "\n",
      "🔍 Checking table 2 for quarters data...\n",
      "   Headers: ['', 'Jun 2022', 'Sep 2022', 'Dec 2022', 'Mar 2023']...\n",
      "✅ Valid quarters table found!\n",
      "   ✅ Clicked 4 expandable elements\n",
      "   ⚠️ Skipping RAW PDF row\n",
      "✅ CONSOLIDATED data found\n",
      "🌐 Fetching STANDALONE: https://www.screener.in/company/RELIANCE/#quarters\n",
      "🤖 Using Selenium for standalone data...\n",
      "📊 Found 12 tables\n",
      "\n",
      "🔍 Checking table 1 for quarters data...\n",
      "   Headers: ['S.No.', 'Name', 'CMP Rs.', 'P/E', 'Mar Cap Rs.Cr.']...\n",
      "\n",
      "🔍 Checking table 2 for quarters data...\n",
      "   Headers: ['', 'Jun 2022', 'Sep 2022', 'Dec 2022', 'Mar 2023']...\n",
      "✅ Valid quarters table found!\n",
      "   ✅ Clicked 4 expandable elements\n",
      "   ⚠️ Skipping RAW PDF row\n",
      "✅ STANDALONE data found\n",
      "\n",
      "💾 Step 3: Saving quarters data for RELIANCE\n",
      "✅ Saved CONSOLIDATED: RELIANCE_Quarters_CONSOLIDATED_20250830_092133.csv\n",
      "📊 Data: 24 rows x 14 columns\n",
      "🔍 Expandable elements clicked: 4\n",
      "✅ Saved STANDALONE: RELIANCE_Quarters_STANDALONE_20250830_092133.csv\n",
      "📊 Data: 22 rows x 14 columns\n",
      "🔍 Expandable elements clicked: 4\n",
      "\n",
      "🔍 Step 4: Verifying saved files\n",
      "\n",
      "📖 File: RELIANCE_Quarters_CONSOLIDATED_20250830_092133.csv\n",
      "📊 Shape: 24 rows x 14 columns\n",
      "🔍 First 5 rows:\n",
      "   Row 1: [nan, 'Jun 2022', 'Sep 2022', 'Dec 2022']...\n",
      "   Row 2: ['Sales -', '218,855', '229,409', '216,737']...\n",
      "   Row 3: ['YOY Sales Growth %', '56.38%', '36.87%', '17.14%']...\n",
      "   Row 4: ['Expenses -', '181,157', '198,438', '181,728']...\n",
      "   Row 5: ['Material Cost %', '67%', '69%', '67%']...\n",
      "⚠️ No expandable data found (may need Selenium)\n",
      "\n",
      "📖 File: RELIANCE_Quarters_STANDALONE_20250830_092133.csv\n",
      "📊 Shape: 22 rows x 14 columns\n",
      "🔍 First 5 rows:\n",
      "   Row 1: [nan, 'Jun 2022', 'Sep 2022', 'Dec 2022']...\n",
      "   Row 2: ['Sales -', '146,478', '137,346', '125,849']...\n",
      "   Row 3: ['YOY Sales Growth %', '70.03%', '41.70%', '13.22%']...\n",
      "   Row 4: ['Expenses -', '125,525', '125,561', '110,950']...\n",
      "   Row 5: ['Material Cost %', '75%', '77%', '75%']...\n",
      "⚠️ No expandable data found (may need Selenium)\n",
      "⏱️  RELIANCE completed in: 28.62 seconds\n",
      "✅ Selenium WebDriver closed\n",
      "\n",
      "============================================================\n",
      "📊 QUARTERS SECTION EXTRACTION SUMMARY\n",
      "============================================================\n",
      "⏱️  TOTAL TIME: 38.50 seconds (0.64 minutes)\n",
      "⏱️  Average per symbol: 38.50 seconds\n",
      "📈 Symbols processed: 1\n",
      "✅ Successful extractions: 1\n",
      "💾 CSV files created: 2\n",
      "\n",
      "⏱️  INDIVIDUAL SYMBOL TIMINGS:\n",
      "   RELIANCE: 28.62 seconds\n",
      "\n",
      "📁 Files created in 'quarterly_data' folder:\n",
      "   - RELIANCE_Quarters_CONSOLIDATED_20250830_092133.csv\n",
      "   - RELIANCE_Quarters_STANDALONE_20250830_092133.csv\n",
      "\n",
      "🎯 FEATURES IMPLEMENTED:\n",
      "✅ 1. RAW PDF rows skipped automatically\n",
      "✅ 2. Expandable rows (+ sign data) extracted with Selenium\n",
      "✅ 3. Timer showing total and per-symbol timing\n",
      "\n",
      "🎯 TO GET + SIGN DATA:\n",
      "💡 1. Install Selenium: pip install selenium\n",
      "💡 2. Download ChromeDriver from: https://chromedriver.chromium.org/\n",
      "💡 3. Make sure ChromeDriver is in your PATH\n",
      "\n",
      "🎉 STEP 1 COMPLETE!\n",
      "💡 Check CSV files for expandable data (indented rows)\n",
      "💡 If no expandable data, install Selenium + ChromeDriver\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Press Enter to exit... \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Try to import Selenium for dynamic content\n",
    "try:\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "    SELENIUM_AVAILABLE = True\n",
    "    print(\"✅ Selenium available - Will extract + sign expandable data\")\n",
    "except ImportError:\n",
    "    SELENIUM_AVAILABLE = False\n",
    "    print(\"⚠️ Selenium not available - Will use basic extraction (no + sign data)\")\n",
    "    print(\"💡 To get + sign data, install: pip install selenium\")\n",
    "\n",
    "class QuarterlyExtractor:\n",
    "    def __init__(self):\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        })\n",
    "        self.base_url = \"https://www.screener.in/company\"\n",
    "        self.results_folder = \"quarterly_data\"\n",
    "        self.use_selenium = SELENIUM_AVAILABLE\n",
    "        self.driver = None\n",
    "        \n",
    "        # Create results folder\n",
    "        if not os.path.exists(self.results_folder):\n",
    "            os.makedirs(self.results_folder)\n",
    "            print(f\"✅ Created folder: {self.results_folder}\")\n",
    "    \n",
    "    def setup_selenium(self):\n",
    "        \"\"\"Setup Selenium WebDriver for dynamic content extraction\"\"\"\n",
    "        if not self.use_selenium:\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            chrome_options = Options()\n",
    "            chrome_options.add_argument('--headless')  # Run in background\n",
    "            chrome_options.add_argument('--no-sandbox')\n",
    "            chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "            chrome_options.add_argument('--disable-gpu')\n",
    "            chrome_options.add_argument('--window-size=1920,1080')\n",
    "            \n",
    "            # Try to create Chrome WebDriver\n",
    "            self.driver = webdriver.Chrome(options=chrome_options)\n",
    "            print(\"✅ Selenium WebDriver initialized\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Selenium setup failed: {e}\")\n",
    "            print(\"💡 Download ChromeDriver from: https://chromedriver.chromium.org/\")\n",
    "            self.use_selenium = False\n",
    "            return False\n",
    "    \n",
    "    def close_selenium(self):\n",
    "        \"\"\"Close Selenium WebDriver\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "            print(\"✅ Selenium WebDriver closed\")\n",
    "    \n",
    "    def read_symbols_from_csv(self, file_path):\n",
    "        \"\"\"Read stock symbols from CSV file\"\"\"\n",
    "        print(f\"\\n🔍 Step 1: Reading symbols from: {file_path}\")\n",
    "        \n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"❌ ERROR: File not found: {file_path}\")\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            symbols = []\n",
    "            \n",
    "            # Read CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "            print(f\"📊 CSV columns found: {list(df.columns)}\")\n",
    "            \n",
    "            # Look for Symbol column\n",
    "            symbol_col = None\n",
    "            for col in df.columns:\n",
    "                if col.lower() in ['symbol', 'symbols', 'stock', 'ticker']:\n",
    "                    symbol_col = col\n",
    "                    break\n",
    "            \n",
    "            if symbol_col:\n",
    "                symbols = df[symbol_col].dropna().tolist()\n",
    "                print(f\"✅ Found {len(symbols)} symbols using column: {symbol_col}\")\n",
    "            else:\n",
    "                symbols = df.iloc[:, 0].dropna().tolist()\n",
    "                print(f\"✅ Using first column, found {len(symbols)} symbols\")\n",
    "            \n",
    "            # Clean symbols\n",
    "            symbols = [symbol.strip().upper() for symbol in symbols if symbol.strip()]\n",
    "            print(f\"📋 Final symbols: {symbols}\")\n",
    "            return symbols\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ ERROR reading CSV: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def extract_quarters_section_data(self, symbol):\n",
    "        \"\"\"Extract data from both standalone and consolidated #quarters sections\"\"\"\n",
    "        print(f\"\\n📈 Step 2: Processing {symbol} - #quarters section\")\n",
    "        \n",
    "        quarters_data = {\n",
    "            'consolidated': None,\n",
    "            'standalone': None\n",
    "        }\n",
    "        \n",
    "        # 1. First, try to get CONSOLIDATED data\n",
    "        try:\n",
    "            consolidated_url = f\"{self.base_url}/{symbol}/consolidated/#quarters\"\n",
    "            print(f\"🌐 Fetching CONSOLIDATED: {consolidated_url}\")\n",
    "            \n",
    "            if self.use_selenium:\n",
    "                consolidated_data = self.extract_with_selenium(consolidated_url, 'consolidated')\n",
    "            else:\n",
    "                consolidated_data = self.extract_with_requests(consolidated_url, 'consolidated')\n",
    "            \n",
    "            if consolidated_data:\n",
    "                quarters_data['consolidated'] = consolidated_data\n",
    "                print(f\"✅ CONSOLIDATED data found\")\n",
    "            else:\n",
    "                print(f\"⚠️ CONSOLIDATED data not available\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error fetching CONSOLIDATED: {e}\")\n",
    "        \n",
    "        # 2. Then, get STANDALONE data  \n",
    "        try:\n",
    "            standalone_url = f\"{self.base_url}/{symbol}/#quarters\"\n",
    "            print(f\"🌐 Fetching STANDALONE: {standalone_url}\")\n",
    "            \n",
    "            if self.use_selenium:\n",
    "                standalone_data = self.extract_with_selenium(standalone_url, 'standalone')\n",
    "            else:\n",
    "                standalone_data = self.extract_with_requests(standalone_url, 'standalone')\n",
    "            \n",
    "            if standalone_data:\n",
    "                quarters_data['standalone'] = standalone_data\n",
    "                print(f\"✅ STANDALONE data found\")\n",
    "            else:\n",
    "                print(f\"⚠️ STANDALONE data not available\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error fetching STANDALONE: {e}\")\n",
    "        \n",
    "        # Check if we got any data\n",
    "        if not quarters_data['consolidated'] and not quarters_data['standalone']:\n",
    "            print(f\"❌ No quarters data found for {symbol}\")\n",
    "            return None\n",
    "        \n",
    "        return quarters_data\n",
    "    \n",
    "    def extract_with_selenium(self, url, data_type):\n",
    "        \"\"\"Extract data using Selenium to handle dynamic content\"\"\"\n",
    "        try:\n",
    "            print(f\"🤖 Using Selenium for {data_type} data...\")\n",
    "            \n",
    "            # Load the page\n",
    "            self.driver.get(url)\n",
    "            \n",
    "            # Wait for page to load\n",
    "            wait = WebDriverWait(self.driver, 10)\n",
    "            \n",
    "            # Look for tables\n",
    "            tables = self.driver.find_elements(By.TAG_NAME, \"table\")\n",
    "            print(f\"📊 Found {len(tables)} tables\")\n",
    "            \n",
    "            for i, table in enumerate(tables):\n",
    "                print(f\"\\n🔍 Checking table {i+1} for quarters data...\")\n",
    "                \n",
    "                # Check if this looks like a quarters table\n",
    "                try:\n",
    "                    headers = table.find_elements(By.TAG_NAME, \"th\")\n",
    "                    if not headers:\n",
    "                        headers = table.find_elements(By.TAG_NAME, \"td\")[:10]  # Get first row as headers\n",
    "                    \n",
    "                    header_texts = [h.text.strip() for h in headers]\n",
    "                    print(f\"   Headers: {header_texts[:5]}...\")\n",
    "                    \n",
    "                    if self.is_valid_quarters_table_selenium(header_texts, table):\n",
    "                        print(f\"✅ Valid quarters table found!\")\n",
    "                        \n",
    "                        # Click all expandable elements (+ signs)\n",
    "                        expandable_elements = self.click_expandable_elements(table)\n",
    "                        \n",
    "                        # Wait a bit for content to load\n",
    "                        time.sleep(2)\n",
    "                        \n",
    "                        # Extract the complete data\n",
    "                        table_data = self.extract_selenium_table_data(table)\n",
    "                        \n",
    "                        return {\n",
    "                            'table_index': i+1,\n",
    "                            'headers': header_texts,\n",
    "                            'data': table_data,\n",
    "                            'type': data_type,\n",
    "                            'expandable_clicked': expandable_elements\n",
    "                        }\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"   ⚠️ Error checking table {i+1}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            print(f\"❌ No valid quarters table found for {data_type}\")\n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Selenium extraction error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def click_expandable_elements(self, table):\n",
    "        \"\"\"Click all + sign elements in the table\"\"\"\n",
    "        clicked_count = 0\n",
    "        \n",
    "        try:\n",
    "            # Look for clickable elements with + signs or expand functionality\n",
    "            expand_selectors = [\n",
    "                \"[class*='expand']\",\n",
    "                \"[class*='plus']\", \n",
    "                \"[class*='toggle']\",\n",
    "                \"span:contains('+')\",\n",
    "                \"button:contains('+')\",\n",
    "                \"[data-toggle]\",\n",
    "                \"[onclick*='expand']\"\n",
    "            ]\n",
    "            \n",
    "            for selector in expand_selectors:\n",
    "                try:\n",
    "                    expandable_elements = table.find_elements(By.CSS_SELECTOR, selector)\n",
    "                    for element in expandable_elements:\n",
    "                        if element.is_displayed() and element.is_enabled():\n",
    "                            try:\n",
    "                                # Scroll into view and click\n",
    "                                self.driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "                                time.sleep(0.5)\n",
    "                                element.click()\n",
    "                                clicked_count += 1\n",
    "                                print(f\"   🔍 Clicked expandable element: {element.text[:20]}\")\n",
    "                                time.sleep(0.5)  # Wait for expansion\n",
    "                            except:\n",
    "                                pass  # Element might not be clickable\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # Also try clicking on elements that contain + in their text\n",
    "            try:\n",
    "                all_elements = table.find_elements(By.XPATH, \".//*[contains(text(), '+')]\")\n",
    "                for element in all_elements:\n",
    "                    if element.is_displayed() and element.tag_name in ['span', 'button', 'td', 'th']:\n",
    "                        try:\n",
    "                            element.click()\n",
    "                            clicked_count += 1\n",
    "                            time.sleep(0.5)\n",
    "                        except:\n",
    "                            pass\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️ Error clicking expandable elements: {e}\")\n",
    "        \n",
    "        if clicked_count > 0:\n",
    "            print(f\"   ✅ Clicked {clicked_count} expandable elements\")\n",
    "        \n",
    "        return clicked_count\n",
    "    \n",
    "    def extract_selenium_table_data(self, table):\n",
    "        \"\"\"Extract table data using Selenium\"\"\"\n",
    "        table_data = []\n",
    "        \n",
    "        try:\n",
    "            rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "            \n",
    "            for row in rows:\n",
    "                cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                if not cells:\n",
    "                    cells = row.find_elements(By.TAG_NAME, \"th\")\n",
    "                \n",
    "                if cells:\n",
    "                    cell_texts = [cell.text.strip() for cell in cells]\n",
    "                    \n",
    "                    # Skip RAW PDF rows\n",
    "                    first_cell = cell_texts[0].upper() if cell_texts else \"\"\n",
    "                    if \"RAW PDF\" in first_cell or \"PDF\" in first_cell:\n",
    "                        print(f\"   ⚠️ Skipping RAW PDF row\")\n",
    "                        continue\n",
    "                    \n",
    "                    if any(cell for cell in cell_texts):  # Only add non-empty rows\n",
    "                        table_data.append(cell_texts)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error extracting table data: {e}\")\n",
    "        \n",
    "        return table_data\n",
    "    \n",
    "    def is_valid_quarters_table_selenium(self, headers, table):\n",
    "        \"\"\"Check if this is a valid quarters table using Selenium\"\"\"\n",
    "        if not headers:\n",
    "            return False\n",
    "        \n",
    "        headers_text = \" \".join(headers).upper()\n",
    "        \n",
    "        # Look for quarterly patterns\n",
    "        quarterly_indicators = ['Q1', 'Q2', 'Q3', 'Q4', 'MAR', 'JUN', 'SEP', 'DEC', 'FY']\n",
    "        quarterly_score = sum(1 for indicator in quarterly_indicators if indicator in headers_text)\n",
    "        \n",
    "        # Check for financial metrics in the table\n",
    "        try:\n",
    "            rows = table.find_elements(By.TAG_NAME, \"tr\")[:10]  # Check first 10 rows\n",
    "            metrics_text = \"\"\n",
    "            for row in rows:\n",
    "                cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                if cells:\n",
    "                    metrics_text += \" \" + cells[0].text.upper()\n",
    "        except:\n",
    "            metrics_text = \"\"\n",
    "        \n",
    "        financial_indicators = ['SALES', 'REVENUE', 'EXPENSES', 'PROFIT', 'OPM', 'EPS']\n",
    "        financial_score = sum(1 for indicator in financial_indicators if indicator in metrics_text)\n",
    "        \n",
    "        return quarterly_score >= 2 and financial_score >= 1\n",
    "    \n",
    "    def extract_with_requests(self, url, data_type):\n",
    "        \"\"\"Fallback extraction using requests (no + sign data)\"\"\"\n",
    "        try:\n",
    "            response = self.session.get(url, timeout=30)\n",
    "            if response.status_code != 200:\n",
    "                return None\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            return self.find_quarters_tables_in_page(soup, data_type)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Requests extraction error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def find_quarters_tables_in_page(self, soup, data_type):\n",
    "        \"\"\"Find quarters tables in the given page (basic extraction)\"\"\"\n",
    "        tables = soup.find_all('table')\n",
    "        \n",
    "        for i, table in enumerate(tables):\n",
    "            headers = []\n",
    "            first_row = table.find('tr')\n",
    "            if first_row:\n",
    "                headers = [th.get_text().strip() for th in first_row.find_all(['th', 'td'])]\n",
    "            \n",
    "            if self.is_valid_quarters_table(headers, table):\n",
    "                table_data = self.extract_basic_table_data(table)\n",
    "                \n",
    "                return {\n",
    "                    'table_index': i+1,\n",
    "                    'headers': headers,\n",
    "                    'data': table_data,\n",
    "                    'type': data_type\n",
    "                }\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def is_valid_quarters_table(self, headers, table):\n",
    "        \"\"\"Check if table contains quarterly data (basic)\"\"\"\n",
    "        if not headers:\n",
    "            return False\n",
    "        \n",
    "        headers_text = \" \".join(headers).upper()\n",
    "        quarterly_indicators = ['Q1', 'Q2', 'Q3', 'Q4', 'MAR', 'JUN', 'SEP', 'DEC', 'FY']\n",
    "        quarterly_score = sum(1 for indicator in quarterly_indicators if indicator in headers_text)\n",
    "        \n",
    "        return quarterly_score >= 2\n",
    "    \n",
    "    def extract_basic_table_data(self, table):\n",
    "        \"\"\"Extract basic table data (no dynamic content)\"\"\"\n",
    "        table_data = []\n",
    "        \n",
    "        try:\n",
    "            rows = table.find_all('tr')\n",
    "            \n",
    "            for row in rows:\n",
    "                cells = [cell.get_text().strip() for cell in row.find_all(['td', 'th'])]\n",
    "                \n",
    "                if cells and any(cell for cell in cells):\n",
    "                    # Skip RAW PDF rows\n",
    "                    first_cell = cells[0].upper() if cells else \"\"\n",
    "                    if \"RAW PDF\" in first_cell or \"PDF\" in first_cell:\n",
    "                        continue\n",
    "                    \n",
    "                    table_data.append(cells)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error extracting basic table data: {e}\")\n",
    "        \n",
    "        return table_data\n",
    "    \n",
    "    def save_quarters_data(self, symbol, quarters_data):\n",
    "        \"\"\"Save quarters data to CSV\"\"\"\n",
    "        print(f\"\\n💾 Step 3: Saving quarters data for {symbol}\")\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        saved_files = []\n",
    "        \n",
    "        # Save Consolidated data if available\n",
    "        if quarters_data['consolidated']:\n",
    "            filename = f\"{symbol}_Quarters_CONSOLIDATED_{timestamp}.csv\"\n",
    "            filepath = os.path.join(self.results_folder, filename)\n",
    "            \n",
    "            data = quarters_data['consolidated']['data']\n",
    "            \n",
    "            with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerows(data)\n",
    "            \n",
    "            print(f\"✅ Saved CONSOLIDATED: {filename}\")\n",
    "            print(f\"📊 Data: {len(data)} rows x {len(data[0]) if data else 0} columns\")\n",
    "            \n",
    "            # Show if expandable data was extracted\n",
    "            if 'expandable_clicked' in quarters_data['consolidated']:\n",
    "                clicked = quarters_data['consolidated']['expandable_clicked']\n",
    "                print(f\"🔍 Expandable elements clicked: {clicked}\")\n",
    "            \n",
    "            saved_files.append(filepath)\n",
    "        \n",
    "        # Save Standalone data if available\n",
    "        if quarters_data['standalone']:\n",
    "            filename = f\"{symbol}_Quarters_STANDALONE_{timestamp}.csv\"\n",
    "            filepath = os.path.join(self.results_folder, filename)\n",
    "            \n",
    "            data = quarters_data['standalone']['data']\n",
    "            \n",
    "            with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerows(data)\n",
    "            \n",
    "            print(f\"✅ Saved STANDALONE: {filename}\")\n",
    "            print(f\"📊 Data: {len(data)} rows x {len(data[0]) if data else 0} columns\")\n",
    "            \n",
    "            # Show if expandable data was extracted\n",
    "            if 'expandable_clicked' in quarters_data['standalone']:\n",
    "                clicked = quarters_data['standalone']['expandable_clicked']\n",
    "                print(f\"🔍 Expandable elements clicked: {clicked}\")\n",
    "            \n",
    "            saved_files.append(filepath)\n",
    "        \n",
    "        return saved_files\n",
    "    \n",
    "    def verify_csv_files(self, csv_files):\n",
    "        \"\"\"Verify and display CSV content\"\"\"\n",
    "        print(f\"\\n🔍 Step 4: Verifying saved files\")\n",
    "        \n",
    "        for filepath in csv_files:\n",
    "            try:\n",
    "                print(f\"\\n📖 File: {os.path.basename(filepath)}\")\n",
    "                df = pd.read_csv(filepath, header=None)\n",
    "                \n",
    "                print(f\"📊 Shape: {df.shape[0]} rows x {df.shape[1]} columns\")\n",
    "                print(f\"🔍 First 5 rows:\")\n",
    "                for i in range(min(5, len(df))):\n",
    "                    row_data = df.iloc[i].tolist()\n",
    "                    print(f\"   Row {i+1}: {row_data[:4]}...\")  # Show first 4 columns\n",
    "                \n",
    "                # Look for expandable data (indented rows)\n",
    "                expandable_count = 0\n",
    "                for i in range(len(df)):\n",
    "                    if df.iloc[i, 0] and str(df.iloc[i, 0]).startswith('  '):\n",
    "                        expandable_count += 1\n",
    "                \n",
    "                if expandable_count > 0:\n",
    "                    print(f\"✅ Found {expandable_count} expandable data rows\")\n",
    "                else:\n",
    "                    print(f\"⚠️ No expandable data found (may need Selenium)\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error reading {filepath}: {e}\")\n",
    "    \n",
    "    def run_quarters_extraction(self):\n",
    "        \"\"\"Main function - Extract from #quarters section only\"\"\"\n",
    "        print(\"🚀 QUARTERS SECTION EXTRACTOR - STEP 1\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"🎯 Consolidated: /company/{symbol}/consolidated/#quarters\")\n",
    "        print(\"🎯 Standalone:   /company/{symbol}/#quarters\")\n",
    "        print(\"📋 Extract: Quarterly Results from both URLs\")\n",
    "        if SELENIUM_AVAILABLE:\n",
    "            print(\"✅ Features: Skip RAW PDF, Extract + sign data, Timer\")\n",
    "        else:\n",
    "            print(\"⚠️ Features: Skip RAW PDF, Basic extraction, Timer\")\n",
    "            print(\"💡 Install Selenium for + sign data: pip install selenium\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # START TIMER\n",
    "        start_time = time.time()\n",
    "        print(f\"⏱️  Started at: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "        \n",
    "        # Setup Selenium if available\n",
    "        if self.use_selenium:\n",
    "            if not self.setup_selenium():\n",
    "                print(\"⚠️ Falling back to basic extraction\")\n",
    "        \n",
    "        # Read symbols\n",
    "        csv_path = r\"E:\\JN\\TestSymbol.csv\"\n",
    "        symbols = self.read_symbols_from_csv(csv_path)\n",
    "        \n",
    "        if not symbols:\n",
    "            print(\"❌ No symbols to process. Exiting.\")\n",
    "            if self.use_selenium:\n",
    "                self.close_selenium()\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n✅ Will process {len(symbols)} symbols\")\n",
    "        \n",
    "        # Process each symbol\n",
    "        total_files_created = []\n",
    "        successful_extractions = 0\n",
    "        symbol_timings = []\n",
    "        \n",
    "        for i, symbol in enumerate(symbols, 1):\n",
    "            symbol_start_time = time.time()\n",
    "            \n",
    "            print(f\"\\n{'='*40} {i}/{len(symbols)} {'='*40}\")\n",
    "            print(f\"🎯 Processing: {symbol} - #quarters section\")\n",
    "            print(f\"⏱️  Symbol started at: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "            \n",
    "            # Add delay between requests\n",
    "            if i > 1:\n",
    "                print(\"⏳ Waiting 3 seconds...\")\n",
    "                time.sleep(3)\n",
    "            \n",
    "            # Extract quarters section data\n",
    "            quarters_data = self.extract_quarters_section_data(symbol)\n",
    "            \n",
    "            if quarters_data:\n",
    "                # Save data\n",
    "                saved_files = self.save_quarters_data(symbol, quarters_data)\n",
    "                total_files_created.extend(saved_files)\n",
    "                successful_extractions += 1\n",
    "                \n",
    "                # Quick verification\n",
    "                self.verify_csv_files(saved_files)\n",
    "            else:\n",
    "                print(f\"⚠️ No quarters section data found for {symbol}\")\n",
    "            \n",
    "            # Symbol timing\n",
    "            symbol_end_time = time.time()\n",
    "            symbol_time = symbol_end_time - symbol_start_time\n",
    "            symbol_timings.append((symbol, symbol_time))\n",
    "            print(f\"⏱️  {symbol} completed in: {symbol_time:.2f} seconds\")\n",
    "        \n",
    "        # Close Selenium\n",
    "        if self.use_selenium:\n",
    "            self.close_selenium()\n",
    "        \n",
    "        # FINAL TIMER & SUMMARY\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"📊 QUARTERS SECTION EXTRACTION SUMMARY\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"⏱️  TOTAL TIME: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
    "        print(f\"⏱️  Average per symbol: {total_time/len(symbols):.2f} seconds\")\n",
    "        print(f\"📈 Symbols processed: {len(symbols)}\")\n",
    "        print(f\"✅ Successful extractions: {successful_extractions}\")\n",
    "        print(f\"💾 CSV files created: {len(total_files_created)}\")\n",
    "        \n",
    "        # Individual symbol timings\n",
    "        if symbol_timings:\n",
    "            print(f\"\\n⏱️  INDIVIDUAL SYMBOL TIMINGS:\")\n",
    "            for symbol, timing in symbol_timings:\n",
    "                print(f\"   {symbol}: {timing:.2f} seconds\")\n",
    "        \n",
    "        if total_files_created:\n",
    "            print(f\"\\n📁 Files created in '{self.results_folder}' folder:\")\n",
    "            for file_path in total_files_created:\n",
    "                print(f\"   - {os.path.basename(file_path)}\")\n",
    "        else:\n",
    "            print(\"❌ No files were created!\")\n",
    "        \n",
    "        print(f\"\\n🎯 FEATURES IMPLEMENTED:\")\n",
    "        print(\"✅ 1. RAW PDF rows skipped automatically\")\n",
    "        if SELENIUM_AVAILABLE:\n",
    "            print(\"✅ 2. Expandable rows (+ sign data) extracted with Selenium\")\n",
    "        else:\n",
    "            print(\"⚠️ 2. Basic extraction only (install Selenium for + sign data)\")\n",
    "        print(\"✅ 3. Timer showing total and per-symbol timing\")\n",
    "        \n",
    "        print(f\"\\n🎯 TO GET + SIGN DATA:\")\n",
    "        print(\"💡 1. Install Selenium: pip install selenium\")\n",
    "        print(\"💡 2. Download ChromeDriver from: https://chromedriver.chromium.org/\")\n",
    "        print(\"💡 3. Make sure ChromeDriver is in your PATH\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"📈 STEP 1: #quarters Section with + Sign Data\")\n",
    "    print(\"🎯 Goal: Extract expandable data (YoY Growth, Material Cost%)\")\n",
    "    print(\"🎯 Method: Selenium for dynamic content + basic fallback\")\n",
    "    print()\n",
    "    \n",
    "    extractor = QuarterlyExtractor()\n",
    "    extractor.run_quarters_extraction()\n",
    "    \n",
    "    print(f\"\\n🎉 STEP 1 COMPLETE!\")\n",
    "    print(\"💡 Check CSV files for expandable data (indented rows)\")\n",
    "    print(\"💡 If no expandable data, install Selenium + ChromeDriver\")\n",
    "    input(\"\\nPress Enter to exit...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
